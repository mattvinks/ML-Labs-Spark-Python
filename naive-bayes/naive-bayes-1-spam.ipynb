{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel='stylesheet' href='../assets/css/main.css'/>\n",
    "\n",
    "[<< back to main index](../README.md)\n",
    "\n",
    "# Naive Bayes Spam Filtering\n",
    "\n",
    "### Overview\n",
    "\n",
    "We all hate spam, so developing a classifier to classify email as spam or not spam is useful.  \n",
    "\n",
    "### Builds on\n",
    "None\n",
    "\n",
    "### Run time\n",
    "approx. 20-30 minutes\n",
    "\n",
    "### Notes\n",
    "\n",
    "PySpark has a class called NaiveBayes that can be used to do Naive Bayes classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Spark...\n",
      "Spark found in :  /home/ubuntu/spark\n",
      "Spark config:\n",
      "\t spark.app.name=TestApp\n",
      "\tspark.master=local[*]\n",
      "\texecutor.memory=2g\n",
      "\tspark.sql.warehouse.dir=/tmp/tmpwf6nthus\n",
      "\tsome_property=some_value\n",
      "Spark UI running on port 4046\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-16-0-107.ec2.internal:4046\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TestApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f12d80fb320>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize Spark Session\n",
    "import os\n",
    "import sys\n",
    "top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "if top_dir not in sys.path:\n",
    "    sys.path.append(top_dir)\n",
    "\n",
    "from init_spark import init_spark\n",
    "spark = init_spark()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Let's load the dataframe\n",
    "\n",
    "We will load the dataframe into spark.  Since the outcome label is \"ham\" or \"spam\", we'll just call it label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [
      "R"
     ],
     "id": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 5.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = spark.read.format(\"csv\").\\\n",
    "          option('header','true').\\\n",
    "          option('delimiter', '\\t').\\\n",
    "          option('inferSchema', 'true').\\\n",
    "          load(\"/data/spam/SMSSpamCollection.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records count : 5,574\n",
      "root\n",
      " |-- isspam: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|isspam|text                                                                                                                                                                                                |\n",
      "+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ham   |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                                                                     |\n",
      "|ham   |Ok lar... Joking wif u oni...                                                                                                                                                                       |\n",
      "|spam  |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's                                         |\n",
      "|ham   |U dun say so early hor... U c already then say...                                                                                                                                                   |\n",
      "|ham   |Nah I don't think he goes to usf, he lives around here though                                                                                                                                       |\n",
      "|spam  |FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv                                                 |\n",
      "|ham   |Even my brother is not like to speak with me. They treat me like aids patent.                                                                                                                       |\n",
      "|ham   |As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune                                    |\n",
      "|spam  |WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.                                       |\n",
      "|spam  |Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030                                          |\n",
      "|ham   |I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.                                                                                       |\n",
      "|spam  |SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info                                                            |\n",
      "|spam  |URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18                                         |\n",
      "|ham   |I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.|\n",
      "|ham   |I HAVE A DATE ON SUNDAY WITH WILL!!                                                                                                                                                                 |\n",
      "|spam  |XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL                                               |\n",
      "|ham   |Oh k...i'm watching here:)                                                                                                                                                                          |\n",
      "|ham   |Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet.                                                                                                                   |\n",
      "|ham   |Fine if thats the way u feel. Thats the way its gota b                                                                                                                                            |\n",
      "|spam  |England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+                                         |\n",
      "+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"records count : {:,}\".format(dataset.count()))\n",
    "\n",
    "dataset.printSchema()\n",
    "dataset.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|isspam|count|\n",
      "+------+-----+\n",
      "|   ham| 4827|\n",
      "|  spam|  747|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Count spam/ham\n",
    "dataset.groupby(\"isspam\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Vectorize using tf/idf\n",
    "\n",
    "Let's use tf/idf for vecorization at first.  TF/IDF will take and count the instances of each term, and then divide by the total frequecy of that term in the entire dataset.  \n",
    "\n",
    "This leads to very highly dimensional data, because every word in the document will lead to a dimension in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|isspam|                text|               words|\n",
      "+------+--------------------+--------------------+\n",
      "|   ham|Go until jurong p...|[go, until, juron...|\n",
      "|   ham|Ok lar... Joking ...|[ok, lar..., joki...|\n",
      "|  spam|Free entry in 2 a...|[free, entry, in,...|\n",
      "|   ham|U dun say so earl...|[u, dun, say, so,...|\n",
      "|   ham|Nah I don't think...|[nah, i, don't, t...|\n",
      "|  spam|FreeMsg Hey there...|[freemsg, hey, th...|\n",
      "|   ham|Even my brother i...|[even, my, brothe...|\n",
      "|   ham|As per your reque...|[as, per, your, r...|\n",
      "|  spam|WINNER!! As a val...|[winner!!, as, a,...|\n",
      "|  spam|Had your mobile 1...|[had, your, mobil...|\n",
      "|   ham|I'm gonna be home...|[i'm, gonna, be, ...|\n",
      "|  spam|SIX chances to wi...|[six, chances, to...|\n",
      "|  spam|URGENT! You have ...|[urgent!, you, ha...|\n",
      "|   ham|I've been searchi...|[i've, been, sear...|\n",
      "|   ham|I HAVE A DATE ON ...|[i, have, a, date...|\n",
      "|  spam|XXXMobileMovieClu...|[xxxmobilemoviecl...|\n",
      "|   ham|Oh k...i'm watchi...|[oh, k...i'm, wat...|\n",
      "|   ham|Eh u remember how...|[eh, u, remember,...|\n",
      "|   ham|Fine if thats th...|[fine, if, thats...|\n",
      "|  spam|England v Macedon...|[england, v, mace...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "## TODO : split the text into words\n",
    "## Hint : outputCol = 'words'\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(dataset)\n",
    "wordsData.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "|isspam|                text|               words|         rawFeatures|            features|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   ham|Go until jurong p...|[go, until, juron...|(2000,[7,77,165,2...|(2000,[7,77,165,2...|\n",
      "|   ham|Ok lar... Joking ...|[ok, lar..., joki...|(2000,[20,484,131...|(2000,[20,484,131...|\n",
      "|  spam|Free entry in 2 a...|[free, entry, in,...|(2000,[30,128,140...|(2000,[30,128,140...|\n",
      "|   ham|U dun say so earl...|[u, dun, say, so,...|(2000,[57,372,381...|(2000,[57,372,381...|\n",
      "|   ham|Nah I don't think...|[nah, i, don't, t...|(2000,[388,426,89...|(2000,[388,426,89...|\n",
      "|  spam|FreeMsg Hey there...|[freemsg, hey, th...|(2000,[68,91,98,9...|(2000,[68,91,98,9...|\n",
      "|   ham|Even my brother i...|[even, my, brothe...|(2000,[47,48,57,2...|(2000,[47,48,57,2...|\n",
      "|   ham|As per your reque...|[as, per, your, r...|(2000,[272,388,39...|(2000,[272,388,39...|\n",
      "|  spam|WINNER!! As a val...|[winner!!, as, a,...|(2000,[74,153,388...|(2000,[74,153,388...|\n",
      "|  spam|Had your mobile 1...|[had, your, mobil...|(2000,[82,279,343...|(2000,[82,279,343...|\n",
      "|   ham|I'm gonna be home...|[i'm, gonna, be, ...|(2000,[26,263,333...|(2000,[26,263,333...|\n",
      "|  spam|SIX chances to wi...|[six, chances, to...|(2000,[15,46,214,...|(2000,[15,46,214,...|\n",
      "|  spam|URGENT! You have ...|[urgent!, you, ha...|(2000,[68,196,388...|(2000,[68,196,388...|\n",
      "|   ham|I've been searchi...|[i've, been, sear...|(2000,[39,185,317...|(2000,[39,185,317...|\n",
      "|   ham|I HAVE A DATE ON ...|[i, have, a, date...|(2000,[44,82,712,...|(2000,[44,82,712,...|\n",
      "|  spam|XXXMobileMovieClu...|[xxxmobilemoviecl...|(2000,[78,273,388...|(2000,[78,273,388...|\n",
      "|   ham|Oh k...i'm watchi...|[oh, k...i'm, wat...|(2000,[275,629,14...|(2000,[275,629,14...|\n",
      "|   ham|Eh u remember how...|[eh, u, remember,...|(2000,[147,236,23...|(2000,[147,236,23...|\n",
      "|   ham|Fine if thats th...|[fine, if, thats...|(2000,[80,170,296...|(2000,[80,170,296...|\n",
      "|  spam|England v Macedon...|[england, v, mace...|(2000,[9,19,45,38...|(2000,[9,19,45,38...|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## compute the hash of words\n",
    "\n",
    "## we will tweak this later\n",
    "number_of_features = 2000\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=number_of_features)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|isspam|                text|            features|\n",
      "+------+--------------------+--------------------+\n",
      "|   ham|Go until jurong p...|(2000,[7,77,165,2...|\n",
      "|   ham|Ok lar... Joking ...|(2000,[20,484,131...|\n",
      "|  spam|Free entry in 2 a...|(2000,[30,128,140...|\n",
      "|   ham|U dun say so earl...|(2000,[57,372,381...|\n",
      "|   ham|Nah I don't think...|(2000,[388,426,89...|\n",
      "|  spam|FreeMsg Hey there...|(2000,[68,91,98,9...|\n",
      "|   ham|Even my brother i...|(2000,[47,48,57,2...|\n",
      "|   ham|As per your reque...|(2000,[272,388,39...|\n",
      "|  spam|WINNER!! As a val...|(2000,[74,153,388...|\n",
      "|  spam|Had your mobile 1...|(2000,[82,279,343...|\n",
      "|   ham|I'm gonna be home...|(2000,[26,263,333...|\n",
      "|  spam|SIX chances to wi...|(2000,[15,46,214,...|\n",
      "|  spam|URGENT! You have ...|(2000,[68,196,388...|\n",
      "|   ham|I've been searchi...|(2000,[39,185,317...|\n",
      "|   ham|I HAVE A DATE ON ...|(2000,[44,82,712,...|\n",
      "|  spam|XXXMobileMovieClu...|(2000,[78,273,388...|\n",
      "|   ham|Oh k...i'm watchi...|(2000,[275,629,14...|\n",
      "|   ham|Eh u remember how...|(2000,[147,236,23...|\n",
      "|   ham|Fine if thats th...|(2000,[80,170,296...|\n",
      "|  spam|England v Macedon...|(2000,[9,19,45,38...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.select(\"isspam\", \"text\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a numeric label out of the string column \"isspam.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+--------------------+\n",
      "|                text|isspam|label|            features|\n",
      "+--------------------+------+-----+--------------------+\n",
      "|Go until jurong p...|   ham|  0.0|(2000,[7,77,165,2...|\n",
      "|Ok lar... Joking ...|   ham|  0.0|(2000,[20,484,131...|\n",
      "|Free entry in 2 a...|  spam|  1.0|(2000,[30,128,140...|\n",
      "|U dun say so earl...|   ham|  0.0|(2000,[57,372,381...|\n",
      "|Nah I don't think...|   ham|  0.0|(2000,[388,426,89...|\n",
      "|FreeMsg Hey there...|  spam|  1.0|(2000,[68,91,98,9...|\n",
      "|Even my brother i...|   ham|  0.0|(2000,[47,48,57,2...|\n",
      "|As per your reque...|   ham|  0.0|(2000,[272,388,39...|\n",
      "|WINNER!! As a val...|  spam|  1.0|(2000,[74,153,388...|\n",
      "|Had your mobile 1...|  spam|  1.0|(2000,[82,279,343...|\n",
      "|I'm gonna be home...|   ham|  0.0|(2000,[26,263,333...|\n",
      "|SIX chances to wi...|  spam|  1.0|(2000,[15,46,214,...|\n",
      "|URGENT! You have ...|  spam|  1.0|(2000,[68,196,388...|\n",
      "|I've been searchi...|   ham|  0.0|(2000,[39,185,317...|\n",
      "|I HAVE A DATE ON ...|   ham|  0.0|(2000,[44,82,712,...|\n",
      "|XXXMobileMovieClu...|  spam|  1.0|(2000,[78,273,388...|\n",
      "|Oh k...i'm watchi...|   ham|  0.0|(2000,[275,629,14...|\n",
      "|Eh u remember how...|   ham|  0.0|(2000,[147,236,23...|\n",
      "|Fine if thats th...|   ham|  0.0|(2000,[80,170,296...|\n",
      "|England v Macedon...|  spam|  1.0|(2000,[9,19,45,38...|\n",
      "+--------------------+------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "## TODO : Index 'isspam' column into 'label' column\n",
    "## Hint : inputCol = 'isspam',   outputCol = 'label'\n",
    "indexer = StringIndexer(inputCol=\"isspam\", outputCol=\"label\")\n",
    "indexed = indexer.fit(rescaledData).transform(rescaledData)\n",
    "\n",
    "indexed.select(['text', 'isspam', 'label', 'features']).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split into training and test\n",
    "\n",
    "We will split our dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set count :  4467\n",
      "testing set count :  1107\n"
     ]
    }
   ],
   "source": [
    "# TODO : Split the data into train and test into 80/20\n",
    "(train, test) = indexed.randomSplit([.8, .2])\n",
    "\n",
    "print(\"training set count : \", train.count())\n",
    "print(\"testing set count : \", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Fit Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "## TODO : create the trainer and set its parameters\n",
    "## Hint : NaiveBayes  (see the class name above)\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training starting...\n",
      "training done.\n",
      "CPU times: user 8 ms, sys: 4 ms, total: 12 ms\n",
      "Wall time: 1.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train the model\n",
    "print(\"training starting...\")\n",
    "## TODO : fit on training data (hint: train)\n",
    "model = nb.fit(train)\n",
    "print(\"training done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run test data\n",
    "\n",
    "Let's call .transform on our model to do make predictions on our test data. The output should be contained in the \"prediction\" column, while the correct label will be there in the \"label\" column. \n",
    "\n",
    "We will be able to evaluate our results by comparing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isspam</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>rawFeatures</th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>&amp;lt;#&amp;gt;  mins but i had to stop somewhere f...</td>\n",
       "      <td>[, &amp;lt;#&amp;gt;, , mins, but, i, had, to, stop, s...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-238.00008767518784, -247.69666065377143]</td>\n",
       "      <td>[0.9999385099060782, 6.149009392179112e-05]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>says that he's quitting at least5times a day ...</td>\n",
       "      <td>[, says, that, he's, quitting, at, least5times...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-1023.6090481114477, -1135.7270521389526]</td>\n",
       "      <td>[1.0, 2.0312787669844803e-49]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>what number do u live at? Is it 11?</td>\n",
       "      <td>[, what, number, do, u, live, at?, is, it, 11?]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-218.51217142825348, -256.8043472202413]</td>\n",
       "      <td>[1.0, 2.3437935430006354e-17]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>\"The world suffers a lot... Not because of the...</td>\n",
       "      <td>[\"the, world, suffers, a, lot..., not, because...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-628.2650041623825, -658.7820364094598]</td>\n",
       "      <td>[0.9999999999999443, 5.579834156193721e-14]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>\"Wen u miss someone, the person is definitely ...</td>\n",
       "      <td>[\"wen, u, miss, someone,, the, person, is, def...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.4288230189921...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-732.4819069852969, -768.2636553158575]</td>\n",
       "      <td>[0.9999999999999998, 2.8852546337894764e-16]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  isspam                                               text  \\\n",
       "0    ham   &lt;#&gt;  mins but i had to stop somewhere f...   \n",
       "1    ham   says that he's quitting at least5times a day ...   \n",
       "2    ham                what number do u live at? Is it 11?   \n",
       "3    ham  \"The world suffers a lot... Not because of the...   \n",
       "4    ham  \"Wen u miss someone, the person is definitely ...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [, &lt;#&gt;, , mins, but, i, had, to, stop, s...   \n",
       "1  [, says, that, he's, quitting, at, least5times...   \n",
       "2    [, what, number, do, u, live, at?, is, it, 11?]   \n",
       "3  [\"the, world, suffers, a, lot..., not, because...   \n",
       "4  [\"wen, u, miss, someone,, the, person, is, def...   \n",
       "\n",
       "                                         rawFeatures  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            features  label  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.4288230189921...    0.0   \n",
       "\n",
       "                                rawPrediction  \\\n",
       "0  [-238.00008767518784, -247.69666065377143]   \n",
       "1  [-1023.6090481114477, -1135.7270521389526]   \n",
       "2   [-218.51217142825348, -256.8043472202413]   \n",
       "3    [-628.2650041623825, -658.7820364094598]   \n",
       "4    [-732.4819069852969, -768.2636553158575]   \n",
       "\n",
       "                                    probability  prediction  \n",
       "0   [0.9999385099060782, 6.149009392179112e-05]         0.0  \n",
       "1                 [1.0, 2.0312787669844803e-49]         0.0  \n",
       "2                 [1.0, 2.3437935430006354e-17]         0.0  \n",
       "3   [0.9999999999999443, 5.579834156193721e-14]         0.0  \n",
       "4  [0.9999999999999998, 2.8852546337894764e-16]         0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select example rows to display.\n",
    "## TODO : transform on test data (hint : test)\n",
    "predictions_test = model.transform(test)\n",
    "predictions_test.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate the model\n",
    "\n",
    "Let's look at how our model performs.  We will do an accuracy measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = model.transform(test)  # hint : test\n",
    "predictions_train = model.transform(train)  # hint : train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy =  0.9691067830758898\n",
      "Test set accuracy =  0.9322493224932249\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "\n",
    "print(\"Training set accuracy = \" , evaluator.evaluate(predictions_train))\n",
    "print(\"Test set accuracy = \" , evaluator.evaluate(predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+\n",
      "|label|  0|  1|\n",
      "+-----+---+---+\n",
      "|  0.0|911| 58|\n",
      "|  1.0| 17|121|\n",
      "+-----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = predictions_test.groupBy('label').pivot('prediction', [0,1]).count().na.fill(0).orderBy('label')\n",
    "cm.show()\n",
    "\n",
    "## Can you explain the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm_pd = cm.toPandas()\n",
    "cm_pd.set_index(\"label\", inplace=True)\n",
    "# print(cm_pd)\n",
    "\n",
    "# colormaps : cmap=\"YlGnBu\" , cmap=\"Greens\", cmap=\"Blues\",  cmap=\"Reds\"\n",
    "sns.heatmap(cm_pd, annot=True, fmt=',', cmap=\"Blues\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Improve prediction results\n",
    "\n",
    "We used too few features above, and got bad accuracy. Increase the number of features for HashingTF.\n",
    "\n",
    "in Step 2, modify the following line `number_of_features = 20`.  \n",
    "Try the following values\n",
    "- 200\n",
    "- 2000\n",
    "- and a large number \n",
    "\n",
    "For each value, record \n",
    "- training / testing accuracy\n",
    "- and confusion matrix\n",
    "\n",
    "Discuss your results in the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9:  Run your own test\n",
    "\n",
    "Now it's your turn!   Make a new dataframe with some sample test data of your own creation.  Make some \"spammy\" SMSes and some ordinary ones.  See how our spam filter does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                text|               words|\n",
      "+--------------------+--------------------+\n",
      "|hey, can we meet ...|[hey,, can, we, m...|\n",
      "|WINNER!  Click he...|[winner!, , click...|\n",
      "|   CHEAP DEGREEES !!|[cheap, degreees,...|\n",
      "|           free food|        [free, food]|\n",
      "|         freee food!|      [freee, food!]|\n",
      "+--------------------+--------------------+\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|               words|         rawFeatures|            features|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|hey, can we meet ...|[hey,, can, we, m...|(2000,[238,486,74...|(2000,[238,486,74...|\n",
      "|WINNER!  Click he...|[winner!, , click...|(2000,[388,493,53...|(2000,[388,493,53...|\n",
      "|   CHEAP DEGREEES !!|[cheap, degreees,...|(2000,[119,339,16...|(2000,[119,339,16...|\n",
      "|           free food|        [free, food]|(2000,[653,1073],...|(2000,[653,1073],...|\n",
      "|         freee food!|      [freee, food!]|(2000,[801,1197],...|(2000,[801,1197],...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: make a dataframe with some of your own data.\n",
    "import pandas as pd\n",
    "\n",
    "mydata = pd.DataFrame({'text' : ['hey, can we meet 1 hr later?', \n",
    "                                'WINNER!  Click here to claim your prize !!!!',\n",
    "                                'CHEAP DEGREEES !!', \n",
    "                                'free food',\n",
    "                                'freee food!']\n",
    "                         })\n",
    "\n",
    "mydata2 = spark.createDataFrame(mydata)\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "fv = tokenizer.transform(mydata2)\n",
    "fv.show()\n",
    "\n",
    "## NOTE : make sure this 'numFeatures' matches the 'numFeatures' in step-2\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=2000)\n",
    "fv = hashingTF.transform(fv)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "fv = idfModel.transform(fv)\n",
    "fv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                text|prediction|\n",
      "+--------------------+----------+\n",
      "|hey, can we meet ...|       0.0|\n",
      "|WINNER!  Click he...|       1.0|\n",
      "|   CHEAP DEGREEES !!|       0.0|\n",
      "|           free food|       1.0|\n",
      "|         freee food!|       0.0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(fv)\n",
    "predictions.select(['text', 'prediction']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUN : How will you defeat this algorithm? :-) \n",
    "\n",
    "If you are spammer, how can you defeat this algorithm?\n",
    "\n",
    "<img src=\"../assets/images/come-tothe-dark-side-iin-we-have-cookies.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "Checkout [Amazon Comprehend](https://us-west-2.console.aws.amazon.com/comprehend/v2/home?region=us-west-2#welcome) to parse natural text and extract meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS: Word2Vec Instead of TF/IDF\n",
    "\n",
    "We used the TF/IDF encoding. We might get better resu\n",
    "\n",
    "lts if we use Word2Vec instead. Run with word2vec and see if you get a better accuracy rate.\n",
    "\n",
    "Refer to [Spark Word2Vec](https://spark.apache.org/docs/2.2.0/mllib-feature-extraction.html#word2vec) implementation for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
