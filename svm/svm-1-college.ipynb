{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines: College Admission\n",
    "\n",
    "Let's look at a classification example in Spark MLLib.  We looked at the college admission before. We can look again at this dataset.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Spark...\n",
      "Spark found in :  /home/ubuntu/spark\n",
      "Spark config:\n",
      "\t executor.memory=2g\n",
      "\tsome_property=some_value\n",
      "\tspark.app.name=TestApp\n",
      "\tspark.master=local[*]\n",
      "\tspark.sql.warehouse.dir=/tmp/tmp4hjkg3iv\n",
      "\tspark.submit.deployMode=client\n",
      "\tspark.ui.showConsoleProgress=true\n",
      "Spark UI running on port 4045\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-16-0-107.ec2.internal:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TestApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f55ac64e278>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize Spark Session\n",
    "import os\n",
    "import sys\n",
    "top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "if top_dir not in sys.path:\n",
    "    sys.path.append(top_dir)\n",
    "\n",
    "from init_spark import init_spark\n",
    "spark = init_spark()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- admit: integer (nullable = true)\n",
      " |-- gre: integer (nullable = true)\n",
      " |-- gpa: double (nullable = true)\n",
      " |-- rank: integer (nullable = true)\n",
      "\n",
      "+-----+---+----+----+\n",
      "|admit|gre| gpa|rank|\n",
      "+-----+---+----+----+\n",
      "|    0|380|3.61|   3|\n",
      "|    1|660|3.67|   3|\n",
      "|    1|800| 4.0|   1|\n",
      "|    0|640|3.19|   4|\n",
      "|    0|520|2.93|   4|\n",
      "|    1|760| 3.0|   2|\n",
      "|    0|560|2.98|   1|\n",
      "|    0|400|3.08|   2|\n",
      "|    0|540|3.39|   3|\n",
      "|    1|700|3.92|   2|\n",
      "|    1|800| 4.0|   4|\n",
      "|    0|440|3.22|   1|\n",
      "|    1|760| 4.0|   1|\n",
      "|    1|700|3.08|   2|\n",
      "|    1|700| 4.0|   1|\n",
      "|    0|480|3.44|   3|\n",
      "|    1|780|3.87|   4|\n",
      "|    0|360|2.56|   3|\n",
      "|    1|800|3.75|   2|\n",
      "|    0|540|3.81|   1|\n",
      "+-----+---+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = spark.read.csv(\"/data/college-admissions/admission-data.csv\", header=True, inferSchema=True)\n",
    "dataset.printSchema()\n",
    "dataset.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.43</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.390699999999998</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>0.49756985195624304</td>\n",
       "      <td>124.46248065545332</td>\n",
       "      <td>0.3971877275408833</td>\n",
       "      <td>1.019803902718557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                admit                 gre                 gpa  \\\n",
       "0   count                  100                 100                 100   \n",
       "1    mean                 0.43               600.0   3.390699999999998   \n",
       "2  stddev  0.49756985195624304  124.46248065545332  0.3971877275408833   \n",
       "3     min                    0                 300                2.42   \n",
       "4     max                    1                 800                 4.0   \n",
       "\n",
       "                rank  \n",
       "0                100  \n",
       "1               2.52  \n",
       "2  1.019803902718557  \n",
       "3                  1  \n",
       "4                  4  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use describe\n",
    "dataset.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|admit|count|\n",
      "+-----+-----+\n",
      "|    1|   43|\n",
      "|    0|   57|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see data spread\n",
    "dataset.groupBy(\"admit\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build the Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+----+----------------+-----+\n",
      "|admit|gre| gpa|rank|        features|label|\n",
      "+-----+---+----+----+----------------+-----+\n",
      "|    0|640|3.19|   4|[640.0,3.19,4.0]|    0|\n",
      "|    0|360|2.56|   3|[360.0,2.56,3.0]|    0|\n",
      "|    0|520| 2.9|   3| [520.0,2.9,3.0]|    0|\n",
      "|    0|660|3.34|   3|[660.0,3.34,3.0]|    0|\n",
      "|    1|800|3.73|   1|[800.0,3.73,1.0]|    1|\n",
      "|    0|480|3.39|   4|[480.0,3.39,4.0]|    0|\n",
      "|    0|580| 4.0|   2| [580.0,4.0,2.0]|    0|\n",
      "|    1|500| 3.6|   3| [500.0,3.6,3.0]|    1|\n",
      "+-----+---+----+----+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "## TODO : input cols : gre, gpa, rank\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['gre', 'gpa', 'rank'], outputCol=\"features\")\n",
    "featureVector = assembler.transform(dataset)\n",
    "featureVector = featureVector.withColumn(\"label\", featureVector[\"admit\"])\n",
    "featureVector.sample(False, 0.1, seed=10).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split into training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set count  81\n",
      "testing set count  19\n"
     ]
    }
   ],
   "source": [
    "## Split into training and test\n",
    "## TODO: create training and test with an 80/20 split\n",
    "(training, test) = featureVector.randomSplit([0.8, 0.2])\n",
    "\n",
    "print (\"training set count \", training.count())\n",
    "print (\"testing set count \", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build the Linear SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "## TODO : set MaxIter to 10\n",
    "lsvc = LinearSVC(maxIter=100, regParam=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training starting...\n",
      "training done.\n",
      "CPU times: user 12 ms, sys: 0 ns, total: 12 ms\n",
      "Wall time: 9.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit the model\n",
    "## TODO : fit on 'training' set\n",
    "print (\"training starting...\")\n",
    "lsvcModel = lsvc.fit(training)\n",
    "print(\"training done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs : gre, gpa, rank\n",
      "Coefficients: [0.0038702344656304007,1.077677265102832,-0.12268785431247]\n",
      "Intercept: -5.916145249988966\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for linearsSVC\n",
    "print (\"inputs : gre, gpa, rank\")\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Iterations\n",
    "\n",
    "If any coefficient is zero, that variable won't be a factor in the decision !  \n",
    "Set **maxIter=50**  and try again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run the test set and get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+----+----------------+-----+--------------------+----------+\n",
      "|admit|gre| gpa|rank|        features|label|       rawPrediction|prediction|\n",
      "+-----+---+----+----+----------------+-----+--------------------+----------+\n",
      "|    1|780|3.22|   2|[780.0,3.22,2.0]|    1|[-0.3273827182089...|       1.0|\n",
      "+-----+---+----+----+----------------+-----+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ## TODO: transform the test data\n",
    "# ## HINT : test\n",
    "# predictions_test = lsvcModel.transform(test)\n",
    "# predictions_test.show()\n",
    "\n",
    "# ## sample\n",
    "# predictions_test.sampleBy(\"label\", fractions={0: 0.5, 1: 0.5}, seed=0).show()\n",
    "predictions_test = lsvcModel.transform(test)\n",
    "predictions_train = lsvcModel.transform(training)\n",
    "predictions_test.sample(False, 0.2).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: See the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = lsvcModel.transform(test)  # Hint : test\n",
    "predictions_train = lsvcModel.transform(training)  # Hint : training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 - Accuracy\n",
    "\n",
    "**TODO: Compare 'training' & 'test' set accuracies**  \n",
    "Can you detect any overfitting / underfitting?\n",
    "\n",
    "\n",
    "**TODO: Increase 'maxIterations' and try again**  \n",
    "Does the accuracy go up?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy : 0.7901234567901234\n",
      "Test accuracy : 0.8421052631578947\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "print(\"Training accuracy :\",  evaluator.evaluate(predictions_train))\n",
    "print(\"Test accuracy :\",  evaluator.evaluate(predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  7.2 - Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+\n",
      "|label|  0|  1|\n",
      "+-----+---+---+\n",
      "|    0| 11|  1|\n",
      "|    1|  2|  5|\n",
      "+-----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = predictions_test.groupBy('label').pivot('prediction', [0,1]).count().na.fill(0).orderBy('label')\n",
    "cm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD8CAYAAABq6S8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAExtJREFUeJzt3XuQnXV9x/H3dzdEkEQSCXcI10BJkItC0KZCHApCiqIOUBgVBG1ERY1oFaQDVDrVsaijxRpXoFzUgK2C6ACSYUAohTYh3IlAQJCQkEgCIeFissm3f+zBHpbd7NnknH3Ob3m/Zp7Z81zOeb4Dmc9+93d+z/NEZiJJKldH1QVIkjaOQS5JhTPIJalwBrkkFc4gl6TCGeSSVDiDXJIKZ5BLUuEMckkq3IiqC+jPZgec7iWnep1Tz/lM1SWoDX3/g3vHxn7GYDLn5bsv3OjzNZMduSQVrm07ckkaUlFuX2uQSxJAR2fVFWwwg1ySAKKthr0HxSCXJHBoRZKKZ0cuSYWzI5ekwtmRS1LhnLUiSYVzaEWSClfw0Eq5v4IkqZmio/FloI+KuCQilkbEA3XbzouIpyPintoyrZ/3HhkRD0fEgog4s5HSDXJJgqYGOXApcGQf27+TmfvXluteV0JEJ/B94ChgInBiREwc6GQOrUgSQGfzvuzMzFsjYpcNeOtkYEFmPg4QEVcCxwAPre9NduSSBD1j5I0uG+70iLivNvQyto/9OwBP1a0vrG1bL4NckmBQQysRMT0i5tYt0xs4ww+A3YH9gcXAt/qqoo9tA94n3aEVSYJBddqZ2QV0DebjM3PJ/58qfgT8uo/DFgI71a3vCCwa6LPtyCUJmv1l5+s/PmK7utUPAg/0cdgcYEJE7BoRI4ETgGsH+mw7ckmCps4jj4hZwFRgXEQsBM4FpkbE/vQMlTwBfLJ27PbARZk5LTO7I+J04DdAJ3BJZj440PkMckmCpl6in5kn9rH54n6OXQRMq1u/Dnjd1MT1McglCbxEX5KKV/Al+ga5JIEduSQVzyCXpMJ5P3JJKpxj5JJUOIdWJKlwduSSVLYwyCWpbAa5JBUuOgxySSqaHbkkFc4gl6TCGeSSVLpyc9wglySwI5ek4nV0eGWnJBXNjlySSldujhvkkgR25JJUPINckgrnJfqSVDg7ckkqnEEuSYUzyCWpcAa5JJWu3Bw3yCUJvERfkorn0IqaZua5H+aoQ/bhj8tXcuBx//zn7Z864VBO+9tD6F67jhtue4Czv/vLCqtU1abuPpYpu4whCG5/4jlufuy5qksqX7k5bpC3myt+dSczr/otF51/0p+3HXLgBI6e+jYOOv7rrF7TzVZjR1VYoaq23eg3MWWXMXzzlidYuy75zF+O54FnVvHHF9dUXVrRmtmRR8QlwNHA0szcp7btX4D3AauBx4BTMvP5Pt77BLASWAt0Z+aBA52vZYNCEfEXEfGViPheRHy39nrvVp1vuLh93mMsX/HSa7ZNP+7dXPDvs1m9phuAPz63qorS1Ca2HT2S3y9/hTVrk3UJjz77EvttP7rqsooXEQ0vDbgUOLLXttnAPpm5L/AIcNZ63v+ezNy/kRCHFgV5RHwFuJKeP1b+F5hTez0rIs5sxTmHsz123popB+zOrZd/iRsv+jzvmDi+6pJUoUUr/8Qe4zZj85GdbNIZTNp2c8ZutknVZRWvmUGembcCy3ttuzEzu2urdwI7Nqv2Vg2tfByYlJmv+VsvIr4NPAh8o0XnHZZGdHYw9i1v5pCTLuDASTvz42+eyt5Hn1d1WarIkpWrmf3IMk6fMp7V3et4esWfWJdZdVnFG+J7rZwKXNXPvgRujIgEfpiZXQN9WKuCfB2wPfBkr+3b1fb1KSKmA9MBRuw4lRHjJrWovLI8veR5rrnpXgDmPvgk69Yl48aO4lmHWN6w7nhyBXc8uQKA90/ciude7h7gHRrIYMbI67OqpquRwK2992ygG/hJP4dMycxFEbE1MDsiflfr8PvVqiCfAdwUEY8CT9W2jQf2AE7v7021/xBdAJsdcLotRs2vbrmPqZP35La7HmWP8VszcpMRhvgb3KiRnaxavZaxm41gv+1Hc8Fvn6i6pOINJsjrs2qQ5ziZni9BD8vs+8+ozFxU+7k0Iq4GJgNDH+SZeUNE7FkrYAd6xscXAnMyc20rzjlcXPb1j/Hud0xg3JhRLLjhfM6feR2XXXMHPzzvw8z9j6+yes1aPnHOFVWXqYr93cE7svnITtZm8rN7n+HlNf3+oasGtXoaeUQcCXwFODQzX+rnmM2BjsxcWXt9BPC1gT67ZdMPM3MdPQP6GoSTz7q0z+2n/sPlQ1uI2tp3bus9aqmN1eTph7OAqcC4iFgInEvPLJU30TNcAnBnZp4WEdsDF2XmNGAb4Ora/hHATzPzhoHO5zxySQI6mvhlZ2ae2Mfmi/s5dhEwrfb6cWC/wZ7PIJckWj+00koGuSTR3I58qBnkkoQduSQVz7sfSlLhCs5xg1ySwAdLSFLx7MglqXCOkUtS4QrOcYNcksCOXJKKV3COG+SSBF7ZKUnFc2hFkgpXcI4b5JIEduSSVLyCc9wglyTwy05JKp5DK5JUOINckgpXcI4b5JIEduSSVLyCc9wglyRw1ookFa+j4JbcIJckHFqRpOL5ZackFa7gIXKDXJLALzslqXiBQS5JRSu4Iaej6gIkqR1ERMNLA591SUQsjYgH6ra9NSJmR8SjtZ9j+3nvybVjHo2Ikxup3SCXJHqmHza6NOBS4Mhe284EbsrMCcBNtfVeNcRbgXOBg4HJwLn9BX49g1yS6LkgqNFlIJl5K7C81+ZjgMtqry8DPtDHW98LzM7M5Zn5HDCb1/9CeB3HyCWJIZm1sk1mLgbIzMURsXUfx+wAPFW3vrC2bb3syCWJwQ2tRMT0iJhbt0xvVhl9bMuB3mRHLkkM7l4rmdkFdA3yFEsiYrtaN74dsLSPYxYCU+vWdwRuGeiD7cgliZ5WuNFlA10LvDoL5WTgl30c8xvgiIgYW/uS84jatvUyyCWJpk8/nAXcAewVEQsj4uPAN4DDI+JR4PDaOhFxYERcBJCZy4HzgTm15Wu1bevl0Iok0dwLgjLzxH52HdbHsXOBT9StXwJcMpjzGeSSxDC+10pEfGh9+zPzF80tR5KqMZxvY/u+9exLwCCXNCwU3JCvP8gz85ShKkSSqlRyR97QrJWI2CYiLo6I62vrE2vfwkrSsDAE0w9bptHph5fSM5dx+9r6I8CMVhQkSVXo7IiGl3bTaJCPy8yfAesAMrMbWNuyqiRpiDVzHvlQa3T64YsRsSW1a/4j4p3AipZVJUlDrA3zuWGNBvkZ9FxeuntE3A5sBRzbsqokaYgN5l4r7aahIM/MeRFxKLAXPWP9D2fmmpZWJklDqOAcbyzII2JT4NPAX9EzvHJbRMzMzFdaVdhzcy5s1UerYB+5Yl7VJWiYasex70Y1OrRyObAS+Nfa+onAFcBxrShKkoZa5xsgyPfKzP3q1m+OiHtbUZAkVaENZxU2rNHph3fXZqoAEBEHA7e3piRJGnod0fjSbga6adb99IyJbwKcFBF/qK3vDDzU+vIkaWgM5zHyo4ekCkmqWDt22o0a6KZZT9av1576vGlLK5KkChTckDc8/fD9wLfoudfKUnqGVuYDk1pXmiQNnREFJ3mjX3aeD7wTeCQzd6XncUV+2Slp2IhofGk3jQb5msxcBnREREdm3gzs38K6JGlIdUQ0vLSbRueRPx8Ro4BbgZ9ExFKgu3VlSdLQasN8blijHfkxwMvAF4AbgMdY/2PgJKkow3Ye+asy88W61ctaVIskVaYdHxjRqIEuCFpJ7R7kvXcBmZlvaUlVkjTECs7xAeeRjx6qQiSpStGWT+NsTKNfdkrSsDZsO3JJeqMwyCWpcMP5plmS9IbQ2ehk7DZkkEsSZT98ueDfQZLUPM26ICgi9oqIe+qWFyJiRq9jpkbEirpjztmY2u3IJYnmXaKfmQ9TuxdVRHQCTwNX93HobZnZlGc+GOSSBHS0Zh75YcBjvZ/t0GwOrUgSg7uNbURMj4i5dcv0fj72BGBWP/veFRH3RsT1EbFRz3awI5ckYMQgJpJnZhfQtb5jImIk8H7grD52zwN2zsxVETENuAaY0Hi1r2VHLkm05MESRwHzMnNJ7x2Z+UJmrqq9vg7YJCLGbWjtduSSREumH55IP8MqEbEtsCQzMyIm09NUL9vQExnkkkRzHywREW8GDgc+WbftNIDMnAkcC3wqIrrpedbDCZnZ151mG2KQSxLNHWfOzJeALXttm1n3+kLgwmadzyCXJMq+stMglyQMckkqXrkxbpBLEtDcLzuHmkEuSXg/ckkqXslXRxrkkoRfdkpS8RxakaTCObQiSYWzI5ekwpUb4wa5JAHQaUcuSWUrOMcNckkCiIIHVwxyScKOXJKK12FHLkllsyOXpMJ5ib4kFa6j3Bw3yCUJnLUiScUreGTFIG9nzyxezNlnfZlly54looNjjzueD3/05KrLUgU+PWU879hpC1a80s0Z18wHYNTITr4wdVe2Hj2SpStX8+1bfs+Lq9dWXGm5Su7IS77h17DXOaKTL335TK751fX8eNZVXDnrpzy2YEHVZakCNy9Yzj/Nfu3/+w/suy33L17JZ3/+EPcvXskH992mouqGh45ofGk3Bnkb22qrrdl74iQANt98FLvtthtLly6puCpVYf6SVaz602u77YPGb8EtC5YBcMuCZRw0fkwVpQ0bHRENL+1myIM8Ik4Z6nMOB08/vZDfzZ/P2/bdr+pS1CbGbDqC51/uBuD5l7vZYlNHSjdGDGJpN1V05P/Y346ImB4RcyNi7sU/6hrKmtraSy++yBdnfI6/P/OrjBo1qupypGGp5I68Jb/CI+K+/nYB/Q7kZWYX0AXwSjfZgtKKs2bNGs6Y8Tmm/c37+OvDj6i6HLWR51/pZsxmPV35mM1GsOKV7qpLKlr7xXPjWvW32DbAe4Hnem0P4L9bdM5hJzM575yz2W233TjpY45I6bXm/mEFU/fYkmvuX8LUPbZkzh9WVF1S2QpO8lYF+a+BUZl5T+8dEXFLi8457Nw97y5+fe0vmbDnnhz/oWMA+OyMM3j3IYdWXJmG2oxDd2HStqMZvekIfnj8Plx192Kuvv8Zvjh1Vw7bc0ueXbWab938+6rLLFo7Dpk0KjLbcwTDoRX15SNXzKu6BLWh/zzl7RudwnMeX9Fw5hy02xZtlfpOP5QkaOq0lYh4IiLuj4h7ImJuH/sjIr4XEQsi4r6IePvGlO58JUmiJVd2viczn+1n31HAhNpyMPCD2s8NYkcuSfTca6XRpQmOAS7PHncCYyJiuw39MINckhjcyEr9NS+1ZXqvj0vgxoi4q499ADsAT9WtL6xt2yAOrUgSEINoteuveenHlMxcFBFbA7Mj4neZeWv96fr62IYL6MWOXJJo7tBKZi6q/VwKXA1M7nXIQmCnuvUdgUUbWrtBLkk0b9JKRGweEaNffQ0cATzQ67BrgZNqs1feCazIzMUbWrtDK5IEzbyycxvg6tpQzQjgp5l5Q0ScBpCZM4HrgGnAAuAlYKMu3TbIJYnmTT/MzMeB192mtBbgr75O4DNNOSEGuSQBPupNkopnkEtS4Up+ZqdBLknYkUtS8QrOcYNckoCik9wglyTKfrCEQS5JFN2QG+SSBBSd5Aa5JOH0Q0kqXsFD5Aa5JEHRIysGuSTB4B4s0W4McknCoRVJKl7BOW6QSxJQdJIb5JKE0w8lqXiOkUtS4ToMckkqXblJbpBLEg6tSFLxCs5xg1ySwI5ckornJfqSVLhyY9wglyTAoRVJKp5XdkpS6crNcYNckqDoHKej6gIkqR10RDS8rE9E7BQRN0fE/Ih4MCI+38cxUyNiRUTcU1vO2Zja7cgliaZ+2dkNfDEz50XEaOCuiJidmQ/1Ou62zDy6GSe0I5ekJsrMxZk5r/Z6JTAf2KGV5zTIJYmejrzRpfHPjF2AA4D/6WP3uyLi3oi4PiImbUztDq1IEoObfhgR04HpdZu6MrOr1zGjgJ8DMzLzhV4fMQ/YOTNXRcQ04BpgwgYVjkEuScDgOu1aaHf1tz8iNqEnxH+Smb/o4/0v1L2+LiL+LSLGZeazgyq6xqEVSaJ5QyvRc9OWi4H5mfntfo7ZtnYcETGZnixetqG125FLEk29snMK8FHg/oi4p7btq8B4gMycCRwLfCoiuoGXgRMyMzf0hAa5JNG86YeZ+V8McH1RZl4IXNicMxrkkgSUfWWnQS5JUHSSG+SSBANeet/OYiPG1zVEImJ67zmqkv8u9CqnH5Zh+sCH6A3IfxcCDHJJKp5BLkmFM8jL4Dio+uK/CwF+2SlJxbMjl6TCGeRtLiKOjIiHI2JBRJxZdT2qXkRcEhFLI+KBqmtRezDI21hEdALfB44CJgInRsTEaqtSG7gUOLLqItQ+DPL2NhlYkJmPZ+Zq4ErgmIprUsUy81ZgedV1qH0Y5O1tB+CpuvWFtPjZf5LKY5C3t75u/uA0I0mvYZC3t4XATnXrOwKLKqpFUpsyyNvbHGBCROwaESOBE4BrK65JUpsxyNtYZnYDpwO/AeYDP8vMB6utSlWLiFnAHcBeEbEwIj5edU2qlld2SlLh7MglqXAGuSQVziCXpMIZ5JJUOINckgpnkEtS4QxySSqcQS5Jhfs/MIl0k+nJIA4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm_pd = cm.toPandas()\n",
    "cm_pd.set_index(\"label\", inplace=True)\n",
    "# print(cm_pd)\n",
    "\n",
    "# colormaps : cmap=\"YlGnBu\" , cmap=\"Greens\", cmap=\"Blues\",  cmap=\"Reds\"\n",
    "sns.heatmap(cm_pd, annot=True, cmap=\"Blues\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 - AUC\n",
    "**=> What does AUC mean?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for training:  0.8666666666666664\n",
      "AUC for test :  0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# default metrics for BinaryClassificationEvaluator is 'areaUnderCurve'\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "# print (\"default metrics : \" ,evaluator.getMetricName())\n",
    "\n",
    "print(\"AUC for training: \" , evaluator.evaluate(predictions_train))\n",
    "print (\"AUC for test : \" , evaluator.evaluate(predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Try running a prediction on your own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gre  gpa  rank\n",
      "0  600  4.0     1\n",
      "1  700  3.5     2\n",
      "2  800  3.2     3\n",
      "+---+---+----+---------------+--------------------+----------+\n",
      "|gre|gpa|rank|       features|       rawPrediction|prediction|\n",
      "+---+---+----+---------------+--------------------+----------+\n",
      "|600|4.0|   1|[600.0,4.0,1.0]|[-0.5940166354881...|       1.0|\n",
      "|700|3.5|   2|[700.0,3.5,2.0]|[-0.3195135951872...|       1.0|\n",
      "|800|3.2|   3|[800.0,3.2,3.0]|[-0.2605460079070...|       1.0|\n",
      "+---+---+----+---------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "newdata = pd.DataFrame({'gre' : [600, 700, 800], \n",
    "                        'gpa' : [4.0, 3.5, 3.2],\n",
    "                        'rank': [1,   2,   3]}\n",
    "             )\n",
    "print(newdata)\n",
    "\n",
    "## TODO : create a spark dataframe\n",
    "## Hint : input is 'newdata'\n",
    "spark_newdata = spark.createDataFrame(newdata)\n",
    "\n",
    "## TODO : create feature vector\n",
    "## Hint : spark_newdata\n",
    "newfeatures = assembler.transform(spark_newdata)\n",
    "\n",
    "lsvcModel.transform(newfeatures).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 : Understanding the impact of Scaling Data\n",
    "Just now we have fed our input vector without scaling to SVM.  \n",
    "IN this section we are going to scale the data and see if it improves the prediction.  \n",
    "We will condense the code to focus on important stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 : Raw data (without scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== run with raw data (not scaled) =======\n",
      "inputs :  gre, gpa, rank\n",
      "Coefficients: [0.004471158074653798,1.2161147145938713,-0.08283634499589466]\n",
      "Intercept: -6.953627550839707\n",
      "Training AUC :  0.8856951871657758\n",
      "Test AUC :  0.8376068376068375\n",
      "Training accuracy 0.7948717948717948\n",
      "Testing accuracy 0.8181818181818182\n",
      "===== END run with raw data (not scaled) =======\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "\n",
    "print (\"===== run with raw data (not scaled) =======\")\n",
    "dataset = spark.read.csv(\"/data/college-admissions/admission-data.csv\", \\\n",
    "                         header=True, inferSchema=True)\n",
    "assembler = VectorAssembler(inputCols=[ 'gre', 'gpa', 'rank'], outputCol=\"features\")\n",
    "featureVector = assembler.transform(dataset)\n",
    "featureVector = featureVector.withColumn(\"label\", featureVector[\"admit\"])\n",
    "(training, test) = featureVector.randomSplit([0.8, 0.2], seed=123)\n",
    "lsvc = LinearSVC(maxIter=100, regParam=0.3, featuresCol='features')\n",
    "lsvcModel = lsvc.fit(training)\n",
    "print (\"inputs :  gre, gpa, rank\")\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))\n",
    "\n",
    "predictions_train = lsvcModel.transform(training)\n",
    "predictions_test = lsvcModel.transform(test)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print (\"Training AUC : \" , evaluator.evaluate(predictions_train))\n",
    "print (\"Test AUC : \" , evaluator.evaluate(predictions_test))  #AUC\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print(\"Training accuracy\",  evaluator.evaluate(predictions_train))\n",
    "print(\"Testing accuracy\",  evaluator.evaluate(predictions_test))\n",
    "print (\"===== END run with raw data (not scaled) =======\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 : Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== run with scaled data  =======\n",
      "+-----+---+----+----+----------------+-----+---------------------------------------------------------+\n",
      "|admit|gre|gpa |rank|features        |label|featuresScaled                                           |\n",
      "+-----+---+----+----+----------------+-----+---------------------------------------------------------+\n",
      "|0    |380|3.61|3   |[380.0,3.61,3.0]|0    |[3.05312892687673,9.088901166082522,2.9417420270727606]  |\n",
      "|1    |660|3.67|3   |[660.0,3.67,3.0]|1    |[5.302802872996426,9.23996323532489,2.9417420270727606]  |\n",
      "|1    |800|4.0 |1   |[800.0,4.0,1.0] |1    |[6.427639846056274,10.070804616157918,0.9805806756909201]|\n",
      "|0    |640|3.19|4   |[640.0,3.19,4.0]|0    |[5.14211187684502,8.03146668138594,3.9223227027636804]   |\n",
      "|0    |520|2.93|4   |[520.0,2.93,4.0]|0    |[4.177965899936578,7.376864381335675,3.9223227027636804] |\n",
      "|1    |760|3.0 |2   |[760.0,3.0,2.0] |1    |[6.10625785375346,7.553103462118439,1.9611613513818402]  |\n",
      "|0    |560|2.98|1   |[560.0,2.98,1.0]|0    |[4.499347892239392,7.5027494390376495,0.9805806756909201]|\n",
      "|0    |400|3.08|2   |[400.0,3.08,2.0]|0    |[3.213819923028137,7.754519554441598,1.9611613513818402] |\n",
      "|0    |540|3.39|3   |[540.0,3.39,3.0]|0    |[4.3386568960879845,8.535006912193836,2.9417420270727606]|\n",
      "|1    |700|3.92|2   |[700.0,3.92,2.0]|1    |[5.62418486529924,9.86938852383476,1.9611613513818402]   |\n",
      "|1    |800|4.0 |4   |[800.0,4.0,4.0] |1    |[6.427639846056274,10.070804616157918,3.9223227027636804]|\n",
      "|0    |440|3.22|1   |[440.0,3.22,1.0]|0    |[3.535201915330951,8.106997716007125,0.9805806756909201] |\n",
      "|1    |760|4.0 |1   |[760.0,4.0,1.0] |1    |[6.10625785375346,10.070804616157918,0.9805806756909201] |\n",
      "|1    |700|3.08|2   |[700.0,3.08,2.0]|1    |[5.62418486529924,7.754519554441598,1.9611613513818402]  |\n",
      "|1    |700|4.0 |1   |[700.0,4.0,1.0] |1    |[5.62418486529924,10.070804616157918,0.9805806756909201] |\n",
      "|0    |480|3.44|3   |[480.0,3.44,3.0]|0    |[3.8565839076337642,8.66089196989581,2.9417420270727606] |\n",
      "|1    |780|3.87|4   |[780.0,3.87,4.0]|1    |[6.266948849904867,9.743503466132786,3.9223227027636804] |\n",
      "|0    |360|2.56|3   |[360.0,2.56,3.0]|0    |[2.892437930725323,6.445314954341068,2.9417420270727606] |\n",
      "|1    |800|3.75|2   |[800.0,3.75,2.0]|1    |[6.427639846056274,9.441379327648049,1.9611613513818402] |\n",
      "|0    |540|3.81|1   |[540.0,3.81,1.0]|0    |[4.3386568960879845,9.592441396890417,0.9805806756909201]|\n",
      "+-----+---+----+----+----------------+-----+---------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "inputs :  gre, gpa, rank\n",
      "Coefficients: [0.556491425374074,0.4830258399185652,-0.0844768279137541]\n",
      "Intercept: -6.95362755084178\n",
      "Training AUC :  0.8856951871657758\n",
      "Test AUC :  0.8376068376068375\n",
      "Training accuracy 0.7948717948717948\n",
      "Testing accuracy 0.8181818181818182\n",
      "===== END run with scaled data =======\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "print (\"===== run with scaled data  =======\")\n",
    "dataset = spark.read.csv(\"/data/college-admissions/admission-data.csv\", \\\n",
    "                         header=True, inferSchema=True)\n",
    "assembler = VectorAssembler(inputCols=[ 'gre', 'gpa', 'rank'], outputCol=\"features\")\n",
    "featureVector = assembler.transform(dataset)\n",
    "featureVector = featureVector.withColumn(\"label\", featureVector[\"admit\"])\n",
    "\n",
    "# scaling\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"featuresScaled\",\n",
    "                        withStd=True, withMean=False)\n",
    "scalerModel = scaler.fit(featureVector)\n",
    "fv_scaled = scalerModel.transform(featureVector)\n",
    "fv_scaled.show(20, truncate=False)\n",
    "\n",
    "(training, test) = fv_scaled.randomSplit([0.8, 0.2], seed=123)  ## CHANGED\n",
    "lsvc = LinearSVC(maxIter=100, regParam=0.3, featuresCol='featuresScaled')  ## CHANGED\n",
    "\n",
    "lsvcModel = lsvc.fit(training)\n",
    "print (\"inputs :  gre, gpa, rank\")\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))\n",
    "\n",
    "predictions_train = lsvcModel.transform(training)\n",
    "predictions_test = lsvcModel.transform(test)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print (\"Training AUC : \" , evaluator.evaluate(predictions_train))\n",
    "print (\"Test AUC : \" , evaluator.evaluate(predictions_test))  #AUC\n",
    "\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "print(\"Training accuracy\",  evaluator.evaluate(predictions_train))\n",
    "print(\"Testing accuracy\",  evaluator.evaluate(predictions_test))\n",
    "\n",
    "print (\"===== END run with scaled data =======\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 : Discuss the findings\n",
    "\n",
    "### Coefficients\n",
    "Here are the coefficients from one sample run\n",
    "\n",
    "raw data run : \n",
    "inputs :  gre, gpa, rank\n",
    "Coefficients: [0.00730924862823,0.803788881405,-0.182571791707]\n",
    "Intercept: -7.016411699283878\n",
    "\n",
    "scaled data run:\n",
    "inputs :  gre, gpa, rank\n",
    "Coefficients: [0.985025239033,0.311565356517,-0.180265498388]\n",
    "Intercept: -7.500693768967119\n",
    "\n",
    "### Accuracy\n",
    "Compare accuracies"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
